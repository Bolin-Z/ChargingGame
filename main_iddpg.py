"""
å……ç”µç«™ä»·æ ¼åšå¼ˆIDDPGè®­ç»ƒä¸»å…¥å£ç¨‹åº

IDDPG (Independent DDPG):
- å®Œå…¨å»ä¸­å¿ƒåŒ–è®­ç»ƒ
- Criticä½¿ç”¨å±€éƒ¨çŠ¶æ€ï¼ˆ48ç»´ï¼‰
- æ¯ä¸ªagentç»´æŠ¤ç‹¬ç«‹çš„ç»éªŒå›æ”¾Buffer
- ä¸“æ³¨äºæ±‚è§£ç”µåŠ¨æ±½è½¦å……ç”µç«™ä»·æ ¼åšå¼ˆä¸­çš„çº³ä»€å‡è¡¡è§£
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.dirname(__file__))
sys.path.insert(0, project_root)

from src.utils.config import get_iddpg_config, get_training_config
from src.trainer.IDDPGTrainer import IDDPGTrainer


def print_results(results):
    """
    æ‰“å°è®­ç»ƒç»“æœæ‘˜è¦

    Args:
        results: è®­ç»ƒç»“æœå­—å…¸
    """
    print("=" * 60)
    print("ğŸ¯ IDDPGå……ç”µç«™ä»·æ ¼åšå¼ˆè®­ç»ƒå®Œæˆ")
    print("=" * 60)

    # åŸºç¡€ç»Ÿè®¡
    print(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡:")
    print(f"   ç®—æ³•ç±»å‹: {results['algorithm']}")
    print(f"   æ€»Episodeæ•°: {results['total_episodes']}")
    print(f"   æ”¶æ•›Episodeæ•°: {results['total_convergences']}")
    print(f"   æ”¶æ•›ç‡: {results['convergence_rate']:.1%}")
    print(f"   å¹³å‡Episodeé•¿åº¦: {results['average_episode_length']:.1f}æ­¥")
    print(f"   æ€»UEä»¿çœŸè¿­ä»£æ•°: {results['total_ue_iterations']}")

    # æ”¶æ•›Episodeåˆ—è¡¨
    if results['convergence_episodes']:
        print(f"âœ… æ”¶æ•›çš„Episodes: {results['convergence_episodes']}")
    else:
        print("âŒ æœªæ‰¾åˆ°æ”¶æ•›çš„Episode")

    # çº³ä»€å‡è¡¡è§£
    nash_eq = results['final_nash_equilibrium']
    if nash_eq['status'] == 'converged':
        total_equilibria = nash_eq['total_equilibria']
        print(f"ğŸ‰ æ‰¾åˆ° {total_equilibria} ä¸ªçº³ä»€å‡è¡¡è§£!")

        # æ˜¾ç¤ºæ‰€æœ‰å‡è¡¡è§£
        for i, equilibrium in enumerate(nash_eq['equilibria'], 1):
            print(f"\nğŸ“Š å‡è¡¡è§£ #{i}:")
            print(f"   æ”¶æ•›Episode: {equilibrium['episode']}")
            print(f"   æ”¶æ•›æ­¥éª¤: {equilibrium['final_step']}")
            print(f"   ç¨³å®šæ­¥æ•°: {equilibrium['stable_steps_count']}")
            print(f"ğŸ’° å‡è¡¡ä»·æ ¼ç­–ç•¥:")
            for agent_id, prices in equilibrium['equilibrium_prices'].items():
                price_str = ", ".join([f"{p:.3f}" for p in prices])
                print(f"   å……ç”µç«™{agent_id}: [{price_str}]")
            print(f"ğŸ’µ å‡è¡¡æ”¶ç›Š:")
            for agent_id, reward in equilibrium['equilibrium_rewards'].items():
                print(f"   å……ç”µç«™{agent_id}: {reward:.2f}")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°çº³ä»€å‡è¡¡: {nash_eq.get('message', 'æœªçŸ¥é”™è¯¯')}")

    print("=" * 60)


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    try:
        print("ğŸš€ å¯åŠ¨IDDPGå……ç”µç«™ä»·æ ¼åšå¼ˆè®­ç»ƒ")
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")

        # 1. åŠ è½½é…ç½®
        print("âš™ï¸  åŠ è½½é…ç½®...")
        iddpg_config = get_iddpg_config()
        training_config = get_training_config()

        print(f"   è®­ç»ƒé…ç½®: æœ€å¤§{training_config.max_episodes}ä¸ªEpisodes, "
              f"æ”¶æ•›é˜ˆå€¼{training_config.convergence_threshold}, "
              f"éšæœºç§å­{training_config.seed}")
        print(f"   ç®—æ³•é…ç½®: Actor-LR={iddpg_config.actor_lr}, "
              f"Critic-LR={iddpg_config.critic_lr}, "
              f"å™ªéŸ³å¼ºåº¦={iddpg_config.noise_sigma}")
        print(f"   IDDPGç‰¹ç‚¹: å®Œå…¨å»ä¸­å¿ƒåŒ–è®­ç»ƒï¼Œå±€éƒ¨çŠ¶æ€Criticï¼ˆ48ç»´ï¼‰")

        # 2. åˆ›å»ºè®­ç»ƒå™¨
        print("ğŸ—ï¸  åˆå§‹åŒ–è®­ç»ƒå™¨...")
        trainer = IDDPGTrainer(iddpg_config, training_config)

        # 3. æ‰§è¡Œè®­ç»ƒ
        print("ğŸ¯ å¼€å§‹å¯»æ‰¾çº³ä»€å‡è¡¡...")
        print()  # ç©ºè¡Œï¼Œä¸ºè®­ç»ƒè¿›åº¦æ¡ç•™å‡ºç©ºé—´

        results = trainer.train()

        # 4. æ‰“å°ç»“æœæ‘˜è¦
        print()  # ç©ºè¡Œåˆ†éš”
        print_results(results)

        print("âœ… è®­ç»ƒç¨‹åºæˆåŠŸå®Œæˆ!")

    except KeyboardInterrupt:
        print("\nâš¡ ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
        return 1

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())