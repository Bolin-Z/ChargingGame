# PLOT.md

本文档记录算法对比实验的可视化方案设计。

## 1. 实验背景

### 1.1 对比算法

| 算法 | 训练范式 | Critic信息维度 | 特点 |
|-----|---------|---------------|------|
| **MADDPG** | 中心化训练，去中心化执行 | 96维（全局） | 基准算法 |
| **MFDDPG** | 独立训练 + Mean Field | 32维（压缩） | 信息压缩 |
| **IDDPG** | 完全独立训练 | 48维（局部） | 去中心化 |

### 1.2 数据集规模

| 数据集 | 节点数 | 链路数 | 充电站数 | 特点 |
|-------|-------|-------|---------|------|
| **Sioux Falls (SF)** | 24 | 76 | 4 | 理论网络，小规模 |
| **Berlin (BF)** | 191 | 451 | 20 | 真实网络，中规模 |
| **Anaheim** | 416 | 914 | 40 | 真实网络，大规模 |

### 1.3 实验设计

- **实验组合**：3算法 × 3数据集 = 9组实验
- **随机种子**：固定（如42），确保可复现
- **每组运行次数**：1次（训练是求解工具，非统计实验）
- **未收敛处理**：记录"未收敛"，使用最后一步结果

---

## 2. 可视化方案

### 2.1 核心图表

| 序号 | 图表类型 | 展示内容 | 用途 |
|-----|---------|---------|------|
| **图1** | 收敛曲线图 | 策略变化率随Step变化 | 对比收敛速度 |
| **表1** | 综合结果表 | 最终均衡的各项指标 | 汇总实验结果 |

### 2.2 收敛曲线图设计

**目标**：展示三个算法在三个数据集上的收敛过程对比

**布局**：3行1列子图（每个数据集一个子图）

**坐标轴**：
- X轴：累积Step数（跨Episode连续编号）
- Y轴：策略变化率（对数坐标）

**曲线**：每个子图3条曲线（MADDPG/MFDDPG/IDDPG）

**示意**：
```
┌─────────────────────────────────┐
│ (a) Sioux Falls                 │
│   Y(log)                        │
│   │ ╲                           │
│   │  ╲___  MADDPG              │
│   │     ╲___  MFDDPG           │
│   │        ╲___  IDDPG         │
│   └────────────────→ Step       │
├─────────────────────────────────┤
│ (b) Berlin Friedrichshain       │
│   ...                           │
├─────────────────────────────────┤
│ (c) Anaheim                     │
│   ...                           │
└─────────────────────────────────┘
```

### 2.3 结果表格设计

| 算法 | 数据集 | 收敛Step | 最终变化率 | 系统总收益 | 平均价格 | 收敛状态 |
|-----|-------|---------|-----------|-----------|---------|---------|
| MADDPG | SF | - | - | - | - | ✓/✗ |
| MFDDPG | SF | - | - | - | - | ✓/✗ |
| IDDPG | SF | - | - | - | - | ✓/✗ |
| MADDPG | BF | - | - | - | - | ✓/✗ |
| MFDDPG | BF | - | - | - | - | ✓/✗ |
| IDDPG | BF | - | - | - | - | ✓/✗ |
| MADDPG | Anaheim | - | - | - | - | ✓/✗ |
| MFDDPG | Anaheim | - | - | - | - | ✓/✗ |
| IDDPG | Anaheim | - | - | - | - | ✓/✗ |

**指标说明**：
- **收敛Step**：达到收敛条件的累积Step数
- **最终变化率**：收敛时的策略变化率
- **系统总收益**：Σ reward_i（所有充电站收益之和）
- **平均价格**：所有充电站所有时段价格的均值

---

## 3. 策略变化率

### 3.1 计算公式

$$\text{策略变化率} = \frac{1}{N \times T} \sum_{i=1}^{N} \sum_{t=1}^{T} \frac{|p_{i,t}^{(k)} - p_{i,t}^{(k-1)}|}{p_{i,t}^{(k-1)} + \epsilon}$$

其中：
- $N$：充电站数量
- $T$：时段数量（8）
- $p_{i,t}^{(k)}$：第k步时充电站i在时段t的价格
- $\epsilon = 10^{-8}$：防止除零

### 3.2 物理意义

| 数值范围 | 含义 |
|---------|------|
| 0.1~0.5 | 策略剧烈调整（训练初期） |
| 0.01~0.1 | 策略逐渐稳定 |
| <0.01 | 接近收敛（收敛阈值） |

### 3.3 代码实现位置

- **计算**：`src/env/EVCSChargingGameEnv.__calculate_relative_change_rate()`
- **记录**：`step_records` 中的 `relative_change_rate` 字段
- **保存**：`results/experiment_{timestamp}/step_records.json`

---

## 4. 数据来源

### 4.1 JSON文件结构

```json
{
  "metadata": {
    "timestamp": "...",
    "total_episodes": 10,
    "total_steps": 150,
    "convergence_episodes": [3, 7],
    "episode_lengths": [20, 15, 10, ...]
  },
  "records": [
    {
      "episode": 0,
      "step": 0,
      "relative_change_rate": Infinity,
      "rewards": {"agent_0": 150.5, "agent_1": 120.3, ...},
      "actual_prices": {"agent_0": [0.5, 0.6, ...], ...},
      "ue_info": {"ue_converged": true, "ue_iterations": 5}
    },
    ...
  ]
}
```

### 4.2 关键字段

| 字段 | 用途 |
|-----|------|
| `relative_change_rate` | 绘制收敛曲线 |
| `rewards` | 计算系统总收益 |
| `actual_prices` | 计算平均价格 |
| `episode`, `step` | 构建X轴（累积Step） |

---

## 5. 充电站数量差异处理

### 5.1 问题

- SF：4个充电站 → 可展示个体
- BF：20个充电站 → 个体展示困难
- Anaheim：40个充电站 → 个体展示不可行

### 5.2 解决策略

| 指标 | 处理方式 |
|-----|---------|
| 收敛速度 | 使用策略变化率（已聚合） |
| 系统收益 | 使用总和 Σ reward_i |
| 价格水平 | 使用均值 ± 标准差 |

**不展示**：每个充电站的详细价格/收益曲线（会议论文篇幅限制）

---

## 6. 实施计划

- [ ] 运行9组实验，收集 step_records.json
- [ ] 编写绘图脚本，生成收敛曲线图
- [ ] 从JSON提取数据，填充结果表格
- [ ] 根据实际结果调整图表细节
