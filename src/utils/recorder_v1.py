"""
å®éªŒè®°å½•ä¸è¾“å‡ºæ¨¡å— (v1)

èŒè´£ï¼š
1. æ”¶é›†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ•°æ®
2. è®­ç»ƒç»“æŸåç»Ÿä¸€ä¿å­˜åˆ° records.json
3. ç”Ÿæˆå®éªŒæ‘˜è¦

æ•°æ®ç»“æ„ä¸æ—§ç³»ç»Ÿ MADDPGTrainer çš„ step_records.json ä¿æŒç›¸ä¼¼é£æ ¼ã€‚
"""

from __future__ import annotations

import json
import os
from dataclasses import dataclass, field, asdict
from datetime import datetime
from typing import TYPE_CHECKING, Any

import numpy as np

if TYPE_CHECKING:
    from ..game.history import EvaluationRecord


@dataclass
class NashConvRecord:
    """NashConv è®¡ç®—è®°å½•"""

    eval_id: int  # å¯¹åº”çš„è¯„ä¼°ç¼–å·
    nashconv: float
    exploitability: float
    regrets: dict[str, float]  # å„ Agent çš„åæ‚”å€¼


@dataclass
class LearnRecord:
    """å­¦ä¹ æ­¥éª¤è®°å½•"""

    eval_id: int  # å¯¹åº”çš„è¯„ä¼°ç¼–å·
    metrics: dict[str, Any]  # å­¦ä¹ æŒ‡æ ‡ï¼ˆactor_loss, critic_loss, grad_norm ç­‰ï¼‰


class ExperimentRecorder:
    """
    å®éªŒè®°å½•å™¨

    æ”¶é›†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œè®­ç»ƒç»“æŸåç»Ÿä¸€ä¿å­˜ã€‚
    """

    def __init__(
        self,
        experiment_name: str,
        agent_names: list[str],
        n_periods: int,
    ):
        """
        åˆå§‹åŒ–è®°å½•å™¨

        Args:
            experiment_name: å®éªŒåç§°
            agent_names: Agent åç§°åˆ—è¡¨
            n_periods: æ—¶æ®µæ•°é‡
        """
        self.experiment_name = experiment_name
        self.agent_names = agent_names
        self.n_periods = n_periods
        self.start_time = datetime.now()

        # è¯„ä¼°è®°å½•ï¼ˆä» GameHistory åŒæ­¥ï¼‰
        self.evaluation_records: list[dict] = []

        # NashConv è®°å½•
        self.nashconv_records: list[NashConvRecord] = []

        # å­¦ä¹ è®°å½•
        self.learn_records: list[LearnRecord] = []

        # ä¿¡å¿µå¿«ç…§ï¼ˆæ¯æ¬¡è¯„ä¼°æ—¶çš„ä¿¡å¿µçŸ©é˜µï¼‰
        self.belief_snapshots: list[np.ndarray] = []

        # ä»·æ ¼å˜åŒ–ç‡å†å²
        self.price_change_history: list[float] = []

    def record_evaluation(
        self,
        record: "EvaluationRecord",
        beliefs: np.ndarray,
        price_change_rate: float | None = None,
    ) -> None:
        """
        è®°å½•ä¸€æ¬¡è¯„ä¼°ç»“æœ

        Args:
            record: GameHistory çš„è¯„ä¼°è®°å½•
            beliefs: è¯„ä¼°æ—¶çš„ä¿¡å¿µçŸ©é˜µ
            price_change_rate: ä»·æ ¼å˜åŒ–ç‡ï¼ˆå¯é€‰ï¼‰
        """
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
        eval_dict = {
            "eval_id": record.eval_id,
            "pure_actions": {
                k: v.tolist() if isinstance(v, np.ndarray) else v
                for k, v in record.pure_actions.items()
            },
            "noisy_actions": {
                k: v.tolist() if isinstance(v, np.ndarray) else v
                for k, v in record.noisy_actions.items()
            },
            "rewards": {k: float(v) for k, v in record.rewards.items()},
            "flows": {
                k: v.tolist() if isinstance(v, np.ndarray) else v
                for k, v in record.flows.items()
            },
            "ue_info": record.ue_info,
        }
        self.evaluation_records.append(eval_dict)

        # ä¿å­˜ä¿¡å¿µå¿«ç…§
        self.belief_snapshots.append(beliefs.copy())

        # ä¿å­˜ä»·æ ¼å˜åŒ–ç‡
        if price_change_rate is not None:
            self.price_change_history.append(price_change_rate)

    def record_nashconv(
        self,
        eval_id: int,
        nashconv: float,
        exploitability: float,
        regrets: dict[str, float],
    ) -> None:
        """
        è®°å½• NashConv è®¡ç®—ç»“æœ

        Args:
            eval_id: å¯¹åº”çš„è¯„ä¼°ç¼–å·
            nashconv: NashConv å€¼
            exploitability: Exploitability å€¼
            regrets: å„ Agent çš„åæ‚”å€¼
        """
        self.nashconv_records.append(
            NashConvRecord(
                eval_id=eval_id,
                nashconv=nashconv,
                exploitability=exploitability,
                regrets=regrets,
            )
        )

    def record_learn(self, eval_id: int, metrics: dict[str, Any]) -> None:
        """
        è®°å½•å­¦ä¹ æ­¥éª¤

        Args:
            eval_id: å¯¹åº”çš„è¯„ä¼°ç¼–å·
            metrics: å­¦ä¹ æŒ‡æ ‡
        """
        self.learn_records.append(LearnRecord(eval_id=eval_id, metrics=metrics))

    def save(
        self,
        output_dir: str,
        converged: bool,
        final_beliefs: np.ndarray,
        total_time: float,
    ) -> str:
        """
        ä¿å­˜æ‰€æœ‰è®°å½•åˆ° JSON æ–‡ä»¶

        Args:
            output_dir: è¾“å‡ºç›®å½•
            converged: æ˜¯å¦æ”¶æ•›
            final_beliefs: æœ€ç»ˆä¿¡å¿µçŸ©é˜µ
            total_time: æ€»è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        os.makedirs(output_dir, exist_ok=True)

        # æ„å»ºå®Œæ•´æ•°æ®
        data = {
            "metadata": {
                "experiment_name": self.experiment_name,
                "agent_names": self.agent_names,
                "n_periods": self.n_periods,
                "start_time": self.start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "total_time_seconds": total_time,
                "total_evaluations": len(self.evaluation_records),
                "total_nashconv_checks": len(self.nashconv_records),
                "total_learns": len(self.learn_records),
                "converged": converged,
            },
            "final_state": {
                "beliefs": final_beliefs.tolist(),
                "final_nashconv": (
                    self.nashconv_records[-1].nashconv
                    if self.nashconv_records
                    else None
                ),
                "final_exploitability": (
                    self.nashconv_records[-1].exploitability
                    if self.nashconv_records
                    else None
                ),
                "final_rewards": (
                    self.evaluation_records[-1]["rewards"]
                    if self.evaluation_records
                    else None
                ),
            },
            "records": self.evaluation_records,
            "nashconv_records": [
                {
                    "eval_id": r.eval_id,
                    "nashconv": r.nashconv,
                    "exploitability": r.exploitability,
                    "regrets": r.regrets,
                }
                for r in self.nashconv_records
            ],
            "learn_records": [
                {"eval_id": r.eval_id, "metrics": r.metrics} for r in self.learn_records
            ],
            "price_change_history": self.price_change_history,
        }

        # ä¿å­˜åˆ°æ–‡ä»¶
        filepath = os.path.join(output_dir, "records.json")
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ å®éªŒæ•°æ®å·²ä¿å­˜åˆ°: {output_dir}")
        print(f"   ğŸ“„ æ•°æ®æ–‡ä»¶: records.json")
        print(f"   ğŸ“Š è¯„ä¼°æ¬¡æ•°: {len(self.evaluation_records)}")
        print(f"   ğŸ“ˆ NashConv æ£€æµ‹æ¬¡æ•°: {len(self.nashconv_records)}")
        print(f"   ğŸ“ å­¦ä¹ æ¬¡æ•°: {len(self.learn_records)}")

        return filepath

    def get_summary(self) -> dict:
        """
        è·å–å®éªŒæ‘˜è¦

        Returns:
            æ‘˜è¦å­—å…¸
        """
        return {
            "total_evaluations": len(self.evaluation_records),
            "total_nashconv_checks": len(self.nashconv_records),
            "total_learns": len(self.learn_records),
            "latest_nashconv": (
                self.nashconv_records[-1].nashconv if self.nashconv_records else None
            ),
            "latest_exploitability": (
                self.nashconv_records[-1].exploitability
                if self.nashconv_records
                else None
            ),
            "latest_rewards": (
                self.evaluation_records[-1]["rewards"]
                if self.evaluation_records
                else None
            ),
        }
